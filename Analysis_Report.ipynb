{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7de2bbbb-6e67-4a76-b0cf-130f6eb78563",
   "metadata": {},
   "source": [
    "# Real-World Analytics Project (RWAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a916ba70-c473-4feb-9f80-5e14df0b5dec",
   "metadata": {},
   "source": [
    "**MEMBERS**\n",
    "*  Vasu Bansal(045055)\n",
    "*  Rishi Goswami(045045)\n",
    "*  Shalini Chauhan(045051)\n",
    "*  Ritika Grover(321156)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Project 2: Report (Sample)\n",
    "\n",
    "Project Title: Classification of Consumer Data into Segments | Clusters | Classes\n",
    "\n",
    "# 1. Project Objectives | Problem Statements\n",
    "\n",
    "A Football Club,aims to leverage data analysis and machine learning to compete effectively against top clubs. They seek to identify key player skills, optimal positions, and team composition to ensure each player performs efficiently and contributes to a strong, cohesive team.\n",
    "\n",
    "    Objective 1 | PS1: Predict the position of players using Supervised Learning Classification Algorithms\n",
    "\n",
    "    Objective 2 | PS2: Identify important features which are classifying positions\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b605069-4fe8-4d0f-adb7-a60a172aa31e",
   "metadata": {},
   "source": [
    "# 2. Description of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3395ed-5b8a-4e88-9103-640c45ae8a42",
   "metadata": {},
   "source": [
    "2.1. Data Source, Size, Shape\r\n",
    "    2.1.1. Data Source (https://www.kaggle.com/datasets/sabir0000/male-football-players-data)\r\n",
    "    2.1.2. Data Sample (24999 KB)\r\n",
    "    2.1.3. Data Shape (161584,101)\r\n",
    "\r\n",
    "2.2. Description of Variables\r\n",
    "    2.2.1. Index Variable(s): Player ID\r\n",
    "    2.2.2. Outcome Variable: Best Position [derived from player position]\r\n",
    "    2.2.3. Input Categorical Variables  \r\n",
    "           2.2.3.2. Input Variables or Features having Nominal Categories:\r\n",
    "           long_name,club_name,club_loaned_from,nationality_name,preferred_foot,body_type,real_face, player_tags,player_traits,league_name,\r\n",
    "\r\n",
    "           2.2.3.3. Input Variables or Features having Ordinal Categories :      \r\n",
    "           Club_Position, National_Position              \r\n",
    "   2.2.4. Input Non-Categorical Variables:\r\n",
    "     age, height_cm, weight_kg, overall_rating, potential, value_eur, wage_eur, international_reputation, skill_moves, release_clause_eur, team_jersey_number, crossing, finishing, heading_accuracy, short_passing, volleys, dribbling, curve, free_kick_accuracy, long_passing,ball_control, acceleration, sprint_speed, agility, reactions, balance, shot_power, jumping, stamina, strength, long_shots, aggression, interceptions, positioning,vision, penalties, composure, defensive_awareness, standing_tackle, sliding_tackle, gk_diving, gk_handling, gk_kicking, gk_positioning, gk_reflexes, nation_jersey_number, mentality, pace, shooting, passing, defending, physic.\r\n",
    "\r\n",
    "\r\n",
    "2.3. Descriptive Statistics\r\n",
    "\r\n",
    "    2.3.1. Descriptive Statistics: Outcome Variable  (Categorical)\r\n",
    "        2.3.1.1. Count | 13\r\n",
    "        Here’s the list of best positions:\r\n",
    "                    Defender\r\n",
    "                    Defender and Midfielder\r\n",
    "                    Defender, Forward\r\n",
    "                    Defender, Forward, Midfielder\r\n",
    "                    Forward\r\n",
    "                    Forward, Midfielder\r\n",
    "                    Goalkeeper\r\n",
    "                    Midfielder\r\n",
    "\r\n",
    "\r\n",
    "    2.3.2. Descriptive Statistics: Input Categorical Variables or Features\r\n",
    "        2.3.2.1. (161584,100)\r\n",
    "\r\n",
    "    2.3.3. Descriptive Statistics: Input Non-Categorical Variables or Features\r\n",
    "     There were in total 93 non-categorical variable with varied statistics\r\n",
    "\r\n",
    "     Example: The statistics for the weight of the players show that the average weight is approximately\r\n",
    "    75.27 kg, with a standard deviation of 7.04 kg, indicating moderate variability around the mean.\r\n",
    "    The minimum recorded weight is 52 kg, while the maximum is 110 kg. The distribution is fairly\r\n",
    "    symmetric. The interquartile range (IQR) is\r\n",
    "    70 kg, with the 25th percentile and 75 at 50% and 80 kg at the 75th percentile at 80 kg, suggesting that the\r\n",
    "    majority of players' weights are within this 10 kg range around the median."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f5b15b-2c79-4dde-8569-f50d1574d3d7",
   "metadata": {},
   "source": [
    "# 3. Analysis of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b1e9af-ade3-423d-abee-4d8dee7e38c1",
   "metadata": {},
   "source": [
    "3.1. Data Pre-Processing\n",
    "    3.1.1. Missing Data Statistics\n",
    "           There were total 17 variables with missing values of <= 20%\n",
    "    3.1.2. Missing Data Treatment Categorical:\n",
    "          Impute with Mode\n",
    "    3.1.3. Missing Data Treatment Non-Categorical:\n",
    "          Impute with Mean\n",
    "    3.1.4. Numerical Encoding of Categorical Variables (Encoding Schema - Alphanumeric Order) using panda's label encoder\n",
    "    3.1.5. Outlier Statistics and Treatment (Scaling | Transformation - MIn-max scalar for outlier treatmentos noncat data by scaling    \n",
    "    3.1.6. Data Bifurcation: Training & Testing Sets [Bifurcation Schema: Stratified Sampling (Based on Outcome Variable or Feature) with {70%} Data in Training Set and {30% } Data in Testing Set]\n",
    "\n",
    "3.2. Data Analysis\n",
    "    3.2.1. PO1 | PS1:: Supervised Machine Learning Classification Algorithm( (Comparison Models) : Logistic Regression| Decision Tree | K Nearest Neighbour|RandomForest| Support Vector Machine\n",
    "    | Metrics Used\n",
    "\n",
    "    3.2.2. PO2 | PS2:: Classification Model Performance Evaluation: Confusion Matrix {Accuracy, Recall, Precision, F1-Score} (Base Model: Decision Tree)\n",
    "\n",
    "\n",
    "3.3 PO3 | PS3:: Variable or Feature Analysis: Base Model (Decision Tree)\n",
    "    List of Relevant or Important Variables or Features and their Thresholds\n",
    "    List of Non-Relevant or Non-Important Variables or Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7311b4d-9e0f-4070-8044-4a70ebf4a00f",
   "metadata": {},
   "source": [
    "# 4. Results | Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaf9f3c-5a6d-4711-8d77-626109d5589b",
   "metadata": {},
   "source": [
    "# Accuracy\n",
    "Decision Tree: 0.96 (Highest accuracy)\n",
    "KNN Classifier: 0.89\n",
    "Random Forest: 0.82\n",
    "Logistic Regression: 0.75\n",
    "SVM: 0.75\n",
    "# Precision\n",
    "Highest Precision:\n",
    "Decision Tree shows the highest precision overall.\n",
    "KNN and Random Forest also perform well but have some low precision in specific classes.\n",
    "Lowest Precision:\n",
    "Logistic Regression and SVM struggle with certain classes, particularly those with small support values.\n",
    "# Recall\n",
    "Highest Recall:\n",
    "Decision Tree consistently achieves high recall, particularly excelling across most classes.\n",
    "KNN also performs well but is less consistent than the Decision Tree.\n",
    "Lowest Recall:\n",
    "Logistic Regression, SVM, and Random Forest have low recall for some classes, particularly those with fewer instances.\n",
    "# F1-Score\n",
    "Highest F1-Score:\n",
    "Decision Tree again leads with the highest F1-scores across most classes.\n",
    "KNN also shows solid F1-scores but with some variability.\n",
    "Lowest F1-Score:\n",
    "Logistic Regression, SVM, and Random Forest exhibit lower F1-scores in specific classes, especially where precision or recall are low.\n",
    "Macro Average & Weighted Average\n",
    "# Macro Average:\n",
    "Decision Tree: Highest (0.79)\n",
    "KNN and Random Forest: Moderate (0.66 and 0.60 respectively)\n",
    "Logistic Regression and SVM: Lower (0.56 and 0.55)\n",
    "# Weighted Average:\n",
    "Decision Tree: Highest (0.96)\n",
    "KNN and Random Forest: Moderate (0.89 and 0.81)\n",
    "Logistic Regression and SVM: Lower (0.74 and 0.75)\n",
    "Overall Performance\n",
    "# Decision Tree is the clear winner with the highest overall performance in terms of accuracy, precision, recall, and F1-score.\n",
    "KNN Classifier performs well but lags behind the Decision Tree, particularly in lower recall for some classes.\n",
    "Random Forest is moderately strong but struggles in some areas, especially with smaller classes.\n",
    "Logistic Regression and SVM show similar performance, both struggling with lower recall and F1-scores in specific classes, leading to lower overall accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb343cbe-3a27-4509-aa2e-f7348ec9d4d1",
   "metadata": {},
   "source": [
    "# 5. Relevant/Important Variables or Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd22ac4-4f93-41f3-91b3-70fc4b775619",
   "metadata": {},
   "source": [
    "## defending_sliding_tackle_mmnorm:\n",
    "\n",
    "Threshold: 0.51\n",
    "This is a primary splitting feature in the tree, indicating its    importance in the model.\n",
    "\n",
    "## goalkeeping_diving_mmnorm:\n",
    "Threshold: 0.42\n",
    "A critical feature for splitting within the branch where defending_sliding_tackle_mmnorm is less than or equal to 0.51.\n",
    "\n",
    "## player_positions_code:\n",
    "Several thresholds (e.g., 207.50, 173.50, 672.00, 93.00, 103.50, 306.50, etc.)\n",
    "This feature is used extensively, indicating its significance in determining the outcome.\n",
    "\n",
    "## mentality_vision_mmnorm:\n",
    "Threshold: 0.53\n",
    "An important feature when defending_sliding_tackle_mmnorm is greater than 0.51.\n",
    "\n",
    "## defending_standing_tackle_mmnorm:\n",
    "Threshold: 0.46\n",
    "Important for a split when mentality_vision_mmnorm is less than or equal to 0.53."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59564e4-024c-4054-bdee-b692f6549fce",
   "metadata": {},
   "source": [
    "# 5. Managerial Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20de82ef-86d3-48b4-94ce-ae00c8364b08",
   "metadata": {},
   "source": [
    "    a) Utilize the Decision Tree model for player position predictions because it provides the highest accuracy (0.96) and consistently strong performance across precision, recall, and F1-scores.\n",
    "    b)Prioritize training in defending and goalkeeping skills as these features (defending_sliding_tackle_mmnorm, goalkeeping_diving_mmnorm) are critical in determining player roles according to the Decision Tree analysis.\n",
    "    c) Assign taller players to heading-intensive roles and shorter, agile players to speed-reliant positions, leveraging height-related feature insights for optimal player performance.\n",
    "    d)Continuously update and refine the Decision Tree model with new data to maintain its effectiveness in player position predictions and adapting to evolving player dynamics.\n",
    "    e) Use the Decision Tree’s high precision and recall to identify and enhance key skills in players that align with successful positions, maximizing their on-field effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73b617d-90fc-4076-b539-b6f08460b23d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
